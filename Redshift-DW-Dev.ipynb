{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dwh.cfg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser\n",
    "import psycopg2\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `configparser` to load all our varibales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST=config.get('CLUSTER', 'HOST')\n",
    "DB_NAME=config.get('CLUSTER', 'DB_NAME')\n",
    "DB_USER=config.get('CLUSTER', 'DB_USER')\n",
    "DB_PASSWORD=config.get('CLUSTER', 'DB_PASSWORD')\n",
    "DB_PORT=config.get('CLUSTER', 'DB_PORT')\n",
    "ARN = config.get('IAM_ROLE', 'ARN')\n",
    "KEY = config.get('AWS','KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.comdwhdwhuserPassw0rd\n"
     ]
    }
   ],
   "source": [
    "# Varify that we can extract all the configurations needed\n",
    "print('{}{}{}{}'.format(*config['CLUSTER'].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to our Redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    }
   ],
   "source": [
    "#conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "# cur = conn.cursor()\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, HOST, DB_PORT, DB_NAME)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our `redshift` and `S3` clients using `boto3` AWS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = boto3.client('redshift',\n",
    "                 aws_access_key_id=KEY,\n",
    "                 aws_secret_access_key=SECRET,\n",
    "                 region_name='us-west-2')\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                 aws_access_key_id=KEY,\n",
    "                 aws_secret_access_key=SECRET,\n",
    "                 region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the cluster is available and running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ClusterIdentifier': 'dwhcluster',\n",
       " 'NodeType': 'dc2.large',\n",
       " 'ClusterStatus': 'available',\n",
       " 'MasterUsername': 'dwhuser',\n",
       " 'Endpoint': {'Address': 'dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com',\n",
       "  'Port': 5439}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['ClusterIdentifier','NodeType','ClusterStatus','MasterUsername','Endpoint']\n",
    "cluster_dict = {k:v for k,v in redshift.describe_clusters()['Clusters'][0].items() if k in keys}\n",
    "cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dentifier = cluster_dict['ClusterIdentifier']\n",
    "# if the status is paused we can run the below to resume the cluster\n",
    "redshift.resume_cluster(ClusterIdentifier=cluster_dentifier)\n",
    "# if the status is avaible and we wish to Pause the cluster we can run the command below\n",
    "# redshift.pause_cluster(ClusterIdentifier=cluster_dentifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Bucket and Folders for the JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = config.get('S3', 'LOG_DATA')\n",
    "log_json = config.get('S3', 'LOG_JSONPATH')\n",
    "song_data = config.get('S3', 'SONG_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://udacity-dend/log_json_path.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDbBucket =  s3.Bucket(\"udacity-dend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the first 5 log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_data/\n",
      "log_data/2018/11/2018-11-01-events.json\n",
      "log_data/2018/11/2018-11-02-events.json\n",
      "log_data/2018/11/2018-11-03-events.json\n",
      "log_data/2018/11/2018-11-04-events.json\n",
      "log_data/2018/11/2018-11-05-events.json\n"
     ]
    }
   ],
   "source": [
    "for i, obj in enumerate(sampleDbBucket.objects.filter(Prefix='log_data')):\n",
    "    print(obj.key)\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the first 5 metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song_data/\n",
      "song_data/A/A/A/TRAAAAK128F9318786.json\n",
      "song_data/A/A/A/TRAAAAV128F421A322.json\n",
      "song_data/A/A/A/TRAAABD128F429CF47.json\n",
      "song_data/A/A/A/TRAAACN128F9355673.json\n",
      "song_data/A/A/A/TRAAAEA128F935A30D.json\n"
     ]
    }
   ],
   "source": [
    "for i, obj in enumerate(sampleDbBucket.objects.filter(Prefix='song_data')):\n",
    "    print(obj.key)\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration using Pandas \n",
    "#### Read our song metadata files into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "for i, obj in enumerate(sampleDbBucket.objects.filter(Prefix='log_data')):\n",
    "    if i == 1:\n",
    "        df = pd.read_json(obj.get()['Body'].read(), lines=True)\n",
    "    elif i > 1:\n",
    "        df = pd.concat([df, pd.read_json(obj.get()['Body'].read(), lines=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8056 entries, 0 to 387\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         6820 non-null   object \n",
      " 1   auth           8056 non-null   object \n",
      " 2   firstName      7770 non-null   object \n",
      " 3   gender         7770 non-null   object \n",
      " 4   itemInSession  8056 non-null   int64  \n",
      " 5   lastName       7770 non-null   object \n",
      " 6   length         6820 non-null   float64\n",
      " 7   level          8056 non-null   object \n",
      " 8   location       7770 non-null   object \n",
      " 9   method         8056 non-null   object \n",
      " 10  page           8056 non-null   object \n",
      " 11  registration   7770 non-null   float64\n",
      " 12  sessionId      8056 non-null   int64  \n",
      " 13  song           6820 non-null   object \n",
      " 14  status         8056 non-null   int64  \n",
      " 15  ts             8056 non-null   int64  \n",
      " 16  userAgent      7770 non-null   object \n",
      " 17  userId         8056 non-null   object \n",
      "dtypes: float64(2), int64(4), object(12)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine our String fields, max length (character) values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist 89.0\n",
      "auth 10\n",
      "firstName 10.0\n",
      "gender 1.0\n",
      "itemInSession int64\n",
      "lastName 9.0\n",
      "length float64\n",
      "level 4\n",
      "location 46.0\n",
      "method 3\n",
      "page 16\n",
      "registration float64\n",
      "sessionId int64\n",
      "song 151.0\n",
      "status int64\n",
      "ts int64\n",
      "userAgent 139.0\n",
      "userId 3.0\n"
     ]
    }
   ],
   "source": [
    "for i in df:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i, df[i].str.len().max())\n",
    "    else:\n",
    "        print(i, df[i].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read our activity log files into a Pandas DataFrame (first `1000` files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "for i, obj in enumerate(sampleDbBucket.objects.filter(Prefix='song_data')):\n",
    "    if i == 1:\n",
    "        df_s = pd.read_json(obj.get()['Body'].read(), lines=True)\n",
    "    elif i > 1:\n",
    "        df_s = pd.concat([df_s, pd.read_json(obj.get()['Body'].read(), lines=True)])\n",
    "    if i >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   artist_id         1000 non-null   object \n",
      " 1   artist_latitude   357 non-null    float64\n",
      " 2   artist_location   1000 non-null   object \n",
      " 3   artist_longitude  357 non-null    float64\n",
      " 4   artist_name       1000 non-null   object \n",
      " 5   duration          1000 non-null   float64\n",
      " 6   num_songs         1000 non-null   int64  \n",
      " 7   song_id           1000 non-null   object \n",
      " 8   title             1000 non-null   object \n",
      " 9   year              1000 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>artist_location</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>song_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARJNIUY12298900C91</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adelitas Way</td>\n",
       "      <td>213.94240</td>\n",
       "      <td>1</td>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>Scream</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR73AIO1187B9AD57B</td>\n",
       "      <td>37.77916</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>-122.42005</td>\n",
       "      <td>Western Addiction</td>\n",
       "      <td>118.07302</td>\n",
       "      <td>1</td>\n",
       "      <td>SOQPWCR12A6D4FB2A3</td>\n",
       "      <td>A Poor Recipe For Civic Cohesion</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>1</td>\n",
       "      <td>SOCIWDW12A8C13D406</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR9Q9YC1187FB5609B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quest_ Pup_ Kevo</td>\n",
       "      <td>252.94322</td>\n",
       "      <td>1</td>\n",
       "      <td>SOFRDWL12A58A7CEF7</td>\n",
       "      <td>Hit Da Scene</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARSVTNL1187B992A91</td>\n",
       "      <td>51.50632</td>\n",
       "      <td>London, England</td>\n",
       "      <td>-0.12714</td>\n",
       "      <td>Jonathan King</td>\n",
       "      <td>129.85424</td>\n",
       "      <td>1</td>\n",
       "      <td>SOEKAZG12AB018837E</td>\n",
       "      <td>I'll Slap Your Face (Entertainment USA Theme)</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            artist_id  artist_latitude    artist_location  artist_longitude  \\\n",
       "0  ARJNIUY12298900C91              NaN                                  NaN   \n",
       "0  AR73AIO1187B9AD57B         37.77916  San Francisco, CA        -122.42005   \n",
       "0  ARMJAGH1187FB546F3         35.14968        Memphis, TN         -90.04892   \n",
       "0  AR9Q9YC1187FB5609B              NaN         New Jersey               NaN   \n",
       "0  ARSVTNL1187B992A91         51.50632    London, England          -0.12714   \n",
       "\n",
       "         artist_name   duration  num_songs             song_id  \\\n",
       "0       Adelitas Way  213.94240          1  SOBLFFE12AF72AA5BA   \n",
       "0  Western Addiction  118.07302          1  SOQPWCR12A6D4FB2A3   \n",
       "0       The Box Tops  148.03546          1  SOCIWDW12A8C13D406   \n",
       "0   Quest_ Pup_ Kevo  252.94322          1  SOFRDWL12A58A7CEF7   \n",
       "0      Jonathan King  129.85424          1  SOEKAZG12AB018837E   \n",
       "\n",
       "                                           title  year  \n",
       "0                                         Scream  2009  \n",
       "0               A Poor Recipe For Civic Cohesion  2005  \n",
       "0                                      Soul Deep  1969  \n",
       "0                                   Hit Da Scene     0  \n",
       "0  I'll Slap Your Face (Entertainment USA Theme)  2001  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist_id 18\n",
      "artist_latitude float64\n",
      "artist_location 44.0\n",
      "artist_longitude float64\n",
      "artist_name 72.0\n",
      "duration float64\n",
      "num_songs int64\n",
      "song_id 18\n",
      "title 86\n",
      "year int64\n"
     ]
    }
   ],
   "source": [
    "for i in df_s:\n",
    "    if df_s[i].dtype == 'object':\n",
    "        print(i, df_s[i].str.len().max())\n",
    "    else:\n",
    "        print(i, df_s[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'auth', 'firstName', 'gender', 'itemInSession', 'lastName',\n",
       "       'length', 'level', 'location', 'method', 'page', 'registration',\n",
       "       'sessionId', 'song', 'status', 'ts', 'userAgent', 'userId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL to Create our Schema for Staging Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE SCHEMA IF NOT EXISTS staging_area;\n",
    "SET search_path TO staging_area;\n",
    "\n",
    "DROP TABLE IF EXISTS staging_events_table;\n",
    "DROP TABLE IF EXISTS staging_songs_table;\n",
    "\n",
    "\n",
    "CREATE TABLE staging_events_table\n",
    "(\n",
    "    artist VARCHAR(250),\n",
    "    auth VARCHAR(10),\n",
    "    firstName VARCHAR(50),\n",
    "    gender VARCHAR(1),\n",
    "    itemInSession SMALLINT,\n",
    "    lastName VARCHAR(50),\n",
    "    length DECIMAL(9,5),\n",
    "    level VARCHAR(4),\n",
    "    location VARCHAR(50),\n",
    "    method VARCHAR(3),\n",
    "    page VARCHAR(16),\n",
    "    registration DOUBLE PRECISION,\n",
    "    sessionId SMALLINT,\n",
    "    song VARCHAR(250),\n",
    "    status SMALLINT,\n",
    "    ts BIGINT, \n",
    "    userAgent VARCHAR(150),\n",
    "    userId VARCHAR(3)\n",
    ");\n",
    "\n",
    "\n",
    "CREATE TABLE staging_songs_table\n",
    "(\n",
    "    artist_id VARCHAR(250),\n",
    "    artist_latitude DECIMAL(9,6),\n",
    "    artist_location VARCHAR(250),\n",
    "    artist_longitude DECIMAL(9,6),\n",
    "    artist_name VARCHAR(250),\n",
    "    duration DECIMAL(9,5),\n",
    "    num_songs SMALLINT,\n",
    "    song_id VARCHAR(20),\n",
    "    title VARCHAR(250),\n",
    "    year SMALLINT\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract (COPY) our Metadata files to a Staging Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy staging_songs_table \n",
    "from 's3://udacity-dend/song_data/'\n",
    "credentials 'aws_iam_role=arn:aws:iam::104737435278:role/dwhRole'\n",
    "region 'us-west-2'\n",
    "json 'auto ignorecase';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract (COPY) our Log files to a Staging Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy staging_events_table \n",
    "from 's3://udacity-dend/log_data/'\n",
    "credentials 'aws_iam_role=arn:aws:iam::104737435278:role/dwhRole'\n",
    "region 'us-west-2'\n",
    "json 's3://udacity-dend/log_json_path.json';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Warehouse Tables (Fact and Dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cofikax0oj2p.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS sparkify;\n",
    "SET search_path TO sparkify;\n",
    "\n",
    "DROP TABLE IF EXISTS fact_songplays;\n",
    "DROP TABLE IF EXISTS dim_users; \n",
    "DROP TABLE IF EXISTS dim_songs;\n",
    "DROP TABLE IF EXISTS dim_artist;\n",
    "DROP TABLE IF EXISTS dim_time;\n",
    "\n",
    "\n",
    "CREATE TABLE dim_users (\n",
    "    user_id smallint,\n",
    "    first_name varchar(50) NOT NULL,\n",
    "    last_name varchar(50) NOT NULL,\n",
    "    gender varchar(1),\n",
    "    level varchar(4) NOT NULL,\n",
    "    PRIMARY KEY(user_id)\n",
    ")\n",
    "DISTSTYLE all\n",
    "SORTKEY(user_id);\n",
    "\n",
    "\n",
    "CREATE TABLE dim_artist (\n",
    "    artist_id varchar(250),\n",
    "    name varchar(250) NOT NULL,\n",
    "    location varchar(250), \n",
    "    latitude DECIMAL(9,6),\n",
    "    longitude DECIMAL(9,6),\n",
    "    PRIMARY KEY(artist_id)\n",
    ")\n",
    "DISTSTYLE KEY\n",
    "DISTKEY(artist_id)\n",
    "SORTKEY(artist_id);\n",
    "\n",
    "CREATE TABLE dim_songs (\n",
    "    song_id varchar(20),\n",
    "    title varchar(250) NOT NULL,\n",
    "    artist_id varchar(250)  NOT NULL,\n",
    "    year smallint,\n",
    "    duration DECIMAL(9,5),\n",
    "    PRIMARY KEY(song_id),\n",
    "    FOREIGN KEY(artist_id) references dim_artist(artist_id)\n",
    ")\n",
    "DISTSTYLE KEY\n",
    "DISTKEY(song_id)\n",
    "SORTKEY(song_id, artist_id)\n",
    ";\n",
    "\n",
    "CREATE TABLE dim_time(\n",
    "    start_time timestamp,\n",
    "    hour smallint,\n",
    "    day smallint,\n",
    "    week smallint,\n",
    "    month smallint, \n",
    "    year smallint, \n",
    "    weekday smallint,\n",
    "    PRIMARY KEY(start_time)\n",
    ")\n",
    "DISTSTYLE KEY\n",
    "DISTKEY(start_time)\n",
    "SORTKEY(start_time);\n",
    "\n",
    "\n",
    "CREATE TABLE fact_songplays (\n",
    "    songplay_id bigint IDENTITY(1,1),\n",
    "    start_time timestamp NOT NULL,\n",
    "    user_id smallint NOT NULL,\n",
    "    level varchar(4),\n",
    "    song_id varchar(20),\n",
    "    artist_id varchar(250),\n",
    "    session_id SMALLINT NOT NULL,\n",
    "    location varchar(50),\n",
    "    user_agent varchar(150),\n",
    "    PRIMARY KEY(songplay_id),\n",
    "    FOREIGN KEY(user_id) references dim_users(user_id),\n",
    "    FOREIGN KEY(song_id) references dim_songs(song_id),\n",
    "    FOREIGN KEY(artist_id) references dim_artist(artist_id),\n",
    "    FOREIGN KEY(start_time) references dim_time(start_time)\n",
    ")\n",
    "DISTSTYLE KEY\n",
    "DISTKEY(start_time)\n",
    "SORTKEY(start_time, user_id, song_id, artist_id)\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
